# 问题列表

**（1）为什么计算机只认识0和1？**

因为最简单的二进制只包含两个值，而最简单的电路也只包含通电和断电两种状态。正是因为这样的相似，所以最初科学家们才使用二进制存储数据。如果要表示更复杂的情况，可以使用多个二进制数字表示（多个bit），对应到电路上也就是多个简单电路的组合而已。（也有人说是“高电平”和"低电平"两种情况）

**（2）计算机为什么不用八进制、十进制、十六进制来存储？**

理论上是可行的，但用电路来实现时太复杂了。比如最简单的八进制有八个值（0到7），因此最简单的电路需要八种状态来表示，太复杂了（难道要用0V-->7V的电压表示？估计计算机设计者要疯）。二进制就简单多了，只有两种状态，电路也天然具备通电和断电两种状态。

如果对生活中的问题进行高度的抽象，都可以把问题抽象为N个只包含“是”和“否”两个选项的问题。

**（3）为什么计算机喜欢用把二进制的值用十六进制表示？**

IBM在bit的基础上创建了byte的概念（8个bit位等于一个byte字节），而1个byte就能包含ASCII所有的字符，比如hello只需要用5个字节就能表示。五个字节相当于32个bit。在高级编程语言中如果显示32个bit对程序员很不友好，因此应该在显示层面用进制更大的方式。

这先普及一个概念：进制越大，你便可以使用更少的位表示更大的值。

```shell
# 十进制   52600
# 二进制   1100110101111000
# 八进制   146570
# 十六进制 cd78
```

以字符串LYN为例，通过查ASCII码表可知，三个字符的各个进制分别是：

```shell
字符          L                   Y                     N
二进制    01001100             01011001              01001110
八进制       114                  131                   116
十进制       76                   78                    89
十六进制     4C                   59                    4E
```

**二进制：**二进制对于人类来说可读性太差，因此不宜在显示层面使用。

**八进制：**一个字节有八位二进制数，而用八进制表示0-->255时最多需要3位。因此当把二进制转为八进制时，可以从右到左，每三位转为一个8进制数。当转换一个字节时最左半边剩余2bit，当转换两个字节时最左边只剩余1个bit。这样非等分的转换方式容易造成困扰，因此也不推荐。

```shell
L:01001100
01     001    100
1       1      4
2bit  3bit    3bit

LY:01001100 01011001
0      100      110       001      011      001
0       4        6         1        3        1
1bit   3bit     3bit      3bit     3bit     3bit
```

**十进制：**十进制表示0-->255时最多需要3位，因此也会遇到8进制的问题。此外二进制在转为十进制时需要涉及乘法，这对计算机开销过大，因此也不推荐。

**十六进制：**十六进制表示0-->255时最多需要2位，因此无论有多少个字符都能实现等分转换，不会遇到八进制的问题。此外十六进制可读性也较好，有效减少二进制位数过多的问题。

```shell
LY:01001100 01011001
0100      1100      0101      1001
 4         C         5         9
```

**（4）负整数如何用二进制表示**

最高位/最左边为0表示正数，为1表示服负数。

```shell
-74：
第一步：得到绝对值：74
第二步：把74转为二进制：01001010
第三步：取反码（0变1,1变0）：10110101
第四步：反码加1：10110110
```

**（5）“有个8位二进制数，值为10110110，它相当于十进制的多少？”**

首先你必须知道它是有符号数还是无符号数？它可能是-74或182

**（6）二进制数如何做减法？**

```shell
4-11=?
#第一步
4的二进制：00000100
-11的二进制：00001011(-11的绝对值)-->11110100(取反码)-->11110101(加1)
#第二步
4-11=4+(-11)
00000100 + 11110101 = 11111001 = -7



```

**（7）如何把带符号的二进制数转为十进制数？**

```shell
11111001    (-7)
#第一步：取反码  00000110
#第二步：加一    00000111  (7)
#第三步：加上符号位-->(-7)

00000110    (6)
# 0开头，证明是正数，因此直接算就行了
```











# reference

* [[Java位操作总结](http://blog.csdn.net/wfzczangpeng/article/details/51819471)](http://blog.csdn.net/wfzczangpeng/article/details/51819471)
* [Java位操作总结](http://blog.csdn.net/wfzczangpeng/article/details/51819471)
* [java中String byte HexString的转换](http://blog.csdn.net/u010350809/article/details/41265379)
* [Java中byte与16进制字符串的互换原理](http://blog.csdn.net/u010963246/article/details/47278501)
* [关于MD5加密中转换byte为十六进制的问题](http://blog.csdn.net/fire_tray/article/details/48391859)
* [将字节数组转换为16进制的三种方案](http://blog.csdn.net/bluezhangfun/article/details/53022655)
* [0x16进制-百度百科](https://baike.baidu.com/item/0x16%E8%BF%9B%E5%88%B6/7402139?fr=aladdin)